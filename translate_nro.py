# -*- coding: utf-8 -*-
# Auther: david082321
# Co-Auther: ChatGPT
# Date: 2025-12-06
# Version: 1.0.0

import os
import re
import json

###############################################
# å·¥å…·å€
###############################################

def extract_strings(nro_path):
    """å¾ NRO è®€å–å¯æ‰“å°å­—ä¸² (UTF-8/ASCII)"""
    strings = {}
    with open(nro_path, "rb") as f:
        data = f.read()
    pattern = re.compile(
        b'(?:[\x20-\x7E]|[\xC2-\xF4][\x80-\xBF]+){2,}'
    )
    for match in pattern.finditer(data):
        offset = match.start()
        text = match.group().decode("utf-8", errors="ignore")
        strings[offset] = text
    return strings


def save_translation_file(strings, out_path):
    # """è¼¸å‡º translation.txt åˆ°è³‡æ–™å¤¾"""
    # with open(out_path, "w", encoding="utf-8") as f:
    #     for offset, text in strings.items():
    #         f.write(f"{offset}:{text}\n")
    """è¼¸å‡º translation.txt åˆ°è³‡æ–™å¤¾ï¼Œç•¥éä¸ç¬¦åˆè¦å‰‡çš„å­—ä¸²"""
    skip_pattern = re.compile(r'[@{}\[\]\(\)#!\*`,\'^]+\|\<')  # ç•¥éçš„å¥‡æ€ªå­—å…ƒ

    with open(out_path, "w", encoding="utf-8") as f:
        for offset, text in strings.items():
            # if len(text.strip()) <= 3:
            #     continue

            # åŒ…å«å¥‡æ€ªå­—å…ƒç•¥é
            if skip_pattern.search(text):
                # continue
                # 3 å€‹å­—å…ƒå…§ç•¥é
                if len(text.strip()) <= 3:
                    continue
            f.write(f"{offset}:{text}\n")


def load_translation_file(path):
    """è®€å– translation.txt"""
    trans = {}
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            if ":" not in line:
                continue
            offset, val = line.rstrip("\n").split(":", 1)
            trans[int(offset)] = val
    return trans


def apply_translation(nro_path, translations, out_path):
    """å°‡ç¿»è­¯å¥—ç”¨åˆ° NROï¼Œæ”¯æ´é•·åº¦è¶…éæˆªæ–·æˆ–æ¨ç§»"""
    with open(nro_path, "rb") as f:
        data = bytearray(f.read())

    offsets_sorted = sorted(translations.keys())
    shift = 0  # ç´¯è¨ˆæ¨ç§»é‡

    for offset in offsets_sorted:
        orig_offset = offset
        offset += shift  # èª¿æ•´ offset

        new_text = translations[orig_offset]
        new_bytes = new_text.encode("utf-8")

        # ä½¿ç”¨åŸå§‹å­—ä¸²é•·åº¦ï¼Œè€Œéé‡åˆ° \x00 åœæ­¢
        old_text = translations.get(orig_offset, None)
        if old_text is None:
            # è‹¥ translations è£¡ä¸å­˜åœ¨åŸå­—ä¸²ï¼Œå°±å¾ data è£¡è®€ 1~255 bytes å‡è¨­é•·åº¦
            old_len = 1
            while offset + old_len < len(data) and data[offset + old_len] != 0:
                old_len += 1
            old_bytes = data[offset:offset + old_len]
        else:
            old_bytes = translations[orig_offset].encode("utf-8")

        # å¦‚æœ new_bytes é•·åº¦è¶…éåŸæœ¬
        if len(new_bytes) > len(old_bytes):
            print(f"\nâš ï¸ é•·åº¦è¶…éåŸæ–‡ï¼ˆåŸ:{len(old_bytes)} / æ–°:{len(new_bytes)}ï¼‰ï¼Œoffset {offset}")
            choice = input("æ˜¯å¦æˆªæ–·å¯«å…¥ï¼Ÿ(Y=æˆªæ–·, N=æ¨ç§»è³‡æ–™) [é è¨­ Y]: ").strip().lower()

            if choice == "" or choice == "y":
                # æˆªæ–·å¯«å…¥
                new_bytes = new_bytes[:len(old_bytes)]
                data[offset:offset + len(new_bytes)] = new_bytes
                continue
            else:
                # æ¨ç§»è³‡æ–™æ¨¡å¼
                diff = len(new_bytes) - len(old_bytes)
                data[offset + len(old_bytes):] = b"\x00" * diff + data[offset + len(old_bytes):]
                data[offset:offset + len(new_bytes)] = new_bytes
                shift += diff  # ç´¯è¨ˆåç§»
                continue

        # æ­£å¸¸è¦†è“‹ï¼ˆå°æ–¼åŸé•·è£œé›¶ï¼‰
        if len(new_bytes) < len(old_bytes):
            new_bytes += b"\x00" * (len(old_bytes) - len(new_bytes))
        data[offset:offset + len(new_bytes)] = new_bytes

    with open(out_path, "wb") as f:
        f.write(data)


###############################################
# å­—å…¸æ©Ÿåˆ¶
###############################################

def load_dict(dict_path):
    if os.path.isfile(dict_path):
        with open(dict_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_dict(dict_path, new_pairs):
    """æ–°å¢/è¦†è“‹è©å…¸ï¼Œä¸æ¸…ç©ºèˆŠè³‡æ–™"""
    old = load_dict(dict_path)
    old.update(new_pairs)
    with open(dict_path, "w", encoding="utf-8") as f:
        json.dump(old, f, ensure_ascii=False, indent=2)


###############################################
# ä¸»æµç¨‹
###############################################

def main():
    script_folder = os.path.dirname(os.path.abspath(__file__))  # A è³‡æ–™å¤¾

    print("è«‹å°‡ NRO / OVL æª”æ¡ˆæ‹–æ›³åˆ°æ­¤è¦–çª—ï¼ŒæŒ‰ Enter:")
    nro_path = input().strip('"').strip()

    if not os.path.isfile(nro_path):
        print("âŒ æª”æ¡ˆä¸å­˜åœ¨ï¼")
        return

    ext = os.path.splitext(nro_path)[1].lower()
    if ext not in [".nro", ".ovl"]:
        print("âŒ åªèƒ½è™•ç† .nro æˆ– .ovlï¼")
        return

    nro_folder = os.path.dirname(os.path.abspath(nro_path))     # B è³‡æ–™å¤¾
    base = os.path.splitext(os.path.basename(nro_path))[0]
    translation_txt = os.path.join(nro_folder, f"{base}_translation.txt")
    dict_path = os.path.join(script_folder, f"{base}_dict.json")

    print("ğŸ” æ­£åœ¨è®€å–å­—ä¸²...")
    strings = extract_strings(nro_path)

    ###############################################
    # è‹¥å­—å…¸å­˜åœ¨ â†’ å•è¦ä¸è¦è‡ªå‹•å¥—ç”¨
    ###############################################
    dict_data = load_dict(dict_path)
    use_dict = False

    if dict_data:
        print(f"åµæ¸¬åˆ°å­—å…¸ {base}_dict.json")
        print("æ˜¯å¦ä½¿ç”¨å­—å…¸è‡ªå‹•æ›¿æ›ï¼Ÿ(Y/N)ï¼š")
        ans = input().strip().lower()
        use_dict = (ans == "y")

    ###############################################
    # ç”¢ç”Ÿ translation.txtï¼ˆå¿…åšï¼‰
    ###############################################
    merged_strings = strings.copy()

    # è‹¥ä½¿ç”¨å­—å…¸ â†’ å®Œå…¨ç¬¦åˆè¡Œæ‰æœƒæ›¿æ›
    if use_dict:
        for off, text in merged_strings.items():
            if text in dict_data:
                merged_strings[off] = dict_data[text]

    save_translation_file(merged_strings, translation_txt)
    print(f"ğŸ“„ å·²ç”Ÿæˆ {translation_txt}")
    print("âš ï¸ è«‹ä¿®æ”¹å¾Œæ‹–å›ä¾†ï¼ŒæŒ‰ Enter:")

    ###############################################
    # ç­‰å¾…ä½¿ç”¨è€…åŒ¯å…¥ç¿»è­¯å¾Œçš„ txt
    ###############################################
    input_txt = input().strip('"').strip()
    if not os.path.isfile(input_txt):
        print("âŒ ç¿»è­¯æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return

    user_trans = load_translation_file(input_txt)

    ###############################################
    # è®Šæ›´åµæ¸¬ï¼šåªæœ‰ä½¿ç”¨è€…æœ‰æ”¹çš„æ‰åŠ å…¥ + å¿…é ˆæ˜¯å¯ç¿»è­¯æ–‡å­—
    ###############################################
    final_apply = {}
    dict_add = {}

    def is_meaningful_text(s):
        if s.strip() == "":
            return False
        if re.search(r'[A-Za-z0-9\u4e00-\u9fff\u3040-\u30ff\uac00-\ud7af]', s):
            return True
        return False

    for offset, orig_text in strings.items():
        if offset not in user_trans:
            continue  # ä½¿ç”¨è€…åˆªæ‰ â†’ ä¸ä¿®æ”¹

        new_text = user_trans[offset].rstrip("\n")

        # åªæœ‰ã€ŒçœŸæ­£ä¸åŒã€æ‰è¦–ç‚ºç¿»è­¯
        if new_text != orig_text:

            # åªå°ã€Œå¯ç¿»è­¯æ–‡å­—ã€åŠ å…¥å­—å…¸
            if is_meaningful_text(orig_text):
                dict_add[orig_text] = new_text

            final_apply[offset] = new_text

    ###############################################
    # å­˜ dictionaryï¼ˆè‹¥æœ‰è®Šæ›´ï¼‰
    ###############################################
    if dict_add:
        print(f"ğŸ“˜ æº–å‚™æ›´æ–°å­—å…¸: {dict_path}ï¼ˆæ–°å¢/ä¿®æ”¹ {len(dict_add)} ç­†ï¼‰")
        ans = input("æ˜¯å¦å„²å­˜æ›´æ–°åˆ°å­—å…¸ï¼Ÿ(Y/N) [é è¨­ Y]: ").strip().lower()
        if ans == "" or ans == "y":
            save_dict(dict_path, dict_add)
            print(f"âœ… å·²æ›´æ–°å­—å…¸: {dict_path}")
        else:
            print("â„¹ï¸ å·²å–æ¶ˆæ›´æ–°å­—å…¸")
    else:
        print("â„¹ï¸ ä½¿ç”¨è€…ç„¡ä¿®æ”¹ â†’ ä¸æ›´æ–°å­—å…¸")

    ###############################################
    # è¼¸å‡º translated.nro
    ###############################################
    out_file = os.path.join(nro_folder, f"{base}_translated{ext}")
    apply_translation(nro_path, final_apply, out_file)
    print(f"âœ… å·²ç”Ÿæˆ {out_file}")

    ###############################################
    # åˆªé™¤ translation.txt
    ###############################################
    try:
        os.remove(translation_txt)
        print(f"ğŸ—‘ï¸ å·²åˆªé™¤ {translation_txt}")
    except:
        pass

    print("ğŸ‰ å®Œæˆï¼")


if __name__ == "__main__":
    main()
